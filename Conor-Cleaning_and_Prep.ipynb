{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021fda1f",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e1816b",
   "metadata": {},
   "source": [
    "The aim of this notebook is to clean and prepare the data in the leavetimes dataset.  \n",
    "The data will be used to build a predictive model that will predict the travel time for a bus route."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a3388",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede2ae6",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff1929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0cc657",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d00ea1",
   "metadata": {},
   "source": [
    "# Bold Print Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157bb6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bold(string):\n",
    "    \"\"\"\n",
    "    Function to print a given string in bold text.\n",
    "    \"\"\"\n",
    "    print(\"\\033[1m\" + string + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e16f1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575409b",
   "metadata": {},
   "source": [
    "# Load Original Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3022da46",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.10 GiB for an array with shape (7, 116949113) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b0c728bd1cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# this may take a couple of minutes and can result in a memory error if many notebooks are in use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_leavetimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/faye/data/rt_leavetimes_DB_2018.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Time to read: {diff}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0mnew_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mform_blocks\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   1748\u001b[0m     \u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FloatBlock\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1750\u001b[0;31m         \u001b[0mfloat_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multi_blockify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FloatBlock\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_multi_blockify\u001b[0;34m(tuples, dtype)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stack_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup_block\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_stack_arrays\u001b[0;34m(tuples, dtype)\u001b[0m\n\u001b[1;32m   1870\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_shape_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1872\u001b[0;31m     \u001b[0mstacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1873\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m         \u001b[0mstacked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 6.10 GiB for an array with shape (7, 116949113) and data type float64"
     ]
    }
   ],
   "source": [
    "# load in original data file using pandas\n",
    "# this may take a couple of minutes and can result in a memory error if many notebooks are in use\n",
    "t1 = datetime.datetime.now()\n",
    "df_leavetimes = pd.read_csv('/home/faye/data/rt_leavetimes_DB_2018.txt', sep=';',error_bad_lines=False)\n",
    "diff = datetime.datetime.now() - t1\n",
    "print(f\"Time to read: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1cef42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load in original data file using a feather file\n",
    "t1 = datetime.datetime.now()\n",
    "df_leavetimes = pd.read_feather('/home/faye/data/leavetimes.feather')\n",
    "diff = datetime.datetime.now() - t1\n",
    "print(f\"Time to read: {diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499a409",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4610094a",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494d91b",
   "metadata": {},
   "source": [
    "- [1. Data Quality Report](#data_quality_report)\n",
    "    - [1.1. Overview of the Dataset](#overview)\n",
    "    - [1.2. Feature Data Types](#feature_data_types)\n",
    "    - [1.3. Duplicates and Constants](#duplicates_and_constants)\n",
    "    - [1.4. Descriptive Statistics for Continuous Features](#desc_stats_continuous)\n",
    "    - [1.5. Descriptive Statistics for Categorical Features](#desc_stats_categorical)\n",
    "    - [1.6. Plotting Continuous Features](#plotting_continuous)\n",
    "    - [1.7. Plotting Categorical Features](#plotting_categorical)\n",
    "    - [1.8. Logical Integrity Check](#logical_integrity_check)\n",
    "    \n",
    "    \n",
    "- [2. Data Quality Plan](#data_quality_plan)\n",
    "    - [2.1. The Plan](#the_plan)\n",
    "    - [2.2. Applying the Solutions](#applying_solutions)  \n",
    "  \n",
    "  \n",
    "- [3. Transforming and Extending Features](#transforming_and_extending)\n",
    "    - [3.1. Add feature: MONTH](#add_month)\n",
    "    - [3.2. Add feature: DAYOFWEEK](#add_dayofweek)\n",
    "    - [3.3. Add feature: DWELLTIME](#add_dwelltime)\n",
    "    - [3.4. Add feature: PLANNEDTIME_TRAVEL](#add_plannedtime_travel)\n",
    "    - [3.5. Add feature: ACTUALTIME_TRAVEL](#add_actualtime_travel)\n",
    "    - [3.6. Add feature: IS_HOLIDAY](#add_isholiday)\n",
    "    - [3.7. Add feature: IS_WEEKDAY](#add_isweekday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47abdf2c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6286d39d",
   "metadata": {},
   "source": [
    "<a id=\"data_quality_report\"></a>\n",
    "# 1. Data Quality Report\n",
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e5f0f6",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## 1.1. Overview of the Dataset\n",
    "[Top of section](#data_quality_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a62ae",
   "metadata": {},
   "source": [
    "> Each entry in the leavetimes dataset contains the actual data for one leave time of one vehicle at one stop point of a route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b012a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows and features\n",
    "num_rows = df_leavetimes.shape[0]\n",
    "features = df_leavetimes.shape[1]\n",
    "print(f\"The dataset has {num_rows} rows with {features} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c677cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print the first 5 rows of the dataset\n",
    "print(\"The first 5 Rows are:\")\n",
    "df_leavetimes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the last 5 rows of the dataset\n",
    "print(\"The last 5 Rows are:\")\n",
    "df_leavetimes.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec091b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ce5c1",
   "metadata": {},
   "source": [
    "<a id=\"feature_data_types\"></a>\n",
    "## 1.2. Feature Data Types\n",
    "[Top of section](#data_quality_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c2659",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print the data type for each feature\n",
    "df_leavetimes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c706c9c",
   "metadata": {},
   "source": [
    "- I am not concerned with the feature DATASOURCE so I will leave it as an object.  \n",
    "- DAYOFSERVICE and LASTUPDATE are dates so I will convert these to datetime objects.  \n",
    "- TRIPID, STOPPOINTID, and VEHICLEID are all unique ID numbers. I will convert these to type category.  \n",
    "- PROGRNUMBER is the sequential position of the stop point in the trip. I will convert this to category.  \n",
    "- PLANNEDTIME_ARR, PLANNEDTIME_DEP, ACTUALTIME_ARR, and ACTUALTIME_DEP are in unit seconds, I will leave these as int64 for the moment.  \n",
    "- PASSENGERS, PASSENGERSIN, and PASSENGERSOUT describe the number of passengers on board, boarding, and descending. I will leave these features as float64.  \n",
    "- DISTANCE describes the distance measured from the beginning of the trip, I will leave this as float64.  \n",
    "- SUPPRESSED is a flag feature. If the leave time is planned and achieved, the record will contain both the planned and actual data. If the leave time is planned and suppressed, the record will contain only the planned data and the SUPRESSED flag will be checked. When the trip is partially suppressed it says the previous link is suppressed (0=achieved,1=suppressed).  \n",
    "- The JUSTIFICATIONID feature is simply described as 'fault code' and listed as a number. I will examine this feature.\n",
    "- The NOTE feature is described as 'free note', I will also need to examine this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b9bda",
   "metadata": {},
   "source": [
    "### 1.2.1. Convert DAYOFSERVICE and LASTUPDATE to datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389020f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert DAYOFSERVICE and LASTUPDATE to datetime object\n",
    "df_leavetimes['DAYOFSERVICE'] = df_leavetimes['DAYOFSERVICE'].astype('datetime64')\n",
    "df_leavetimes['LASTUPDATE'] = df_leavetimes['LASTUPDATE'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546512d5",
   "metadata": {},
   "source": [
    "### 1.2.2. Convert TRIPID, STOPPOINTID, VEHICLEID, and PROGRNUMBER to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31b0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the selected columns to type category\n",
    "cols = ['TRIPID', 'STOPPOINTID', 'VEHICLEID', 'PROGRNUMBER']\n",
    "\n",
    "for col in cols:\n",
    "    df_leavetimes[col] = df_leavetimes[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8112f1f0",
   "metadata": {},
   "source": [
    "### 1.2.3. Convert SUPPRESSED to boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert SUPPRESSED to boolean\n",
    "df_leavetimes['SUPPRESSED'] = df_leavetimes['SUPPRESSED'].astype('boolean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce712395",
   "metadata": {},
   "source": [
    "### 1.2.4. Examine JUSTIFICATIONID and NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a84efd",
   "metadata": {},
   "source": [
    "#### JUSTIFICATIONID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd73d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the unique values of the JUSTIFICATIONID feature\n",
    "df_leavetimes['JUSTIFICATIONID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55169b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of unique values for the JUSTIFICATIONID feature\n",
    "len(df_leavetimes['JUSTIFICATIONID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299a85a",
   "metadata": {},
   "source": [
    "> In the Concept Design document for the database, from which this data has come, we see that JUSTIFICATIONID is used as a foreign key to link to a justifications table whose data we do not have.  \n",
    "As we are missing the key data to which this feature relates I believe it will be unusable for modelling an there for I will drop this feature later. \n",
    "For the moment I will convert this feature to type category as it is a unique identification number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3066c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert JUSTIFICATIONID to type category\n",
    "df_leavetimes['JUSTIFICATIONID'] = df_leavetimes['JUSTIFICATIONID'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61495590",
   "metadata": {},
   "source": [
    "#### NOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b324d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the unique values for the NOTE feature\n",
    "df_leavetimes['NOTE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571eccd1",
   "metadata": {},
   "source": [
    "> The NOTE feature is a constant column of missing values. This will be dealt with later so I will leave the data type as float64."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a667fe",
   "metadata": {},
   "source": [
    "### 1.2.5. Converted Feature Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6829e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display the datatype of each feature\n",
    "df_leavetimes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all categorical columns\n",
    "categorical_columns = df_leavetimes[\n",
    "    ['DATASOURCE', 'TRIPID', 'PROGRNUMBER', 'STOPPOINTID', \n",
    "     'VEHICLEID', 'SUPPRESSED', 'JUSTIFICATIONID'\n",
    "    ]\n",
    "].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all continuous columns\n",
    "continuous_columns = df_leavetimes[\n",
    "    ['DAYOFSERVICE', 'PLANNEDTIME_ARR', 'PLANNEDTIME_DEP', 'ACTUALTIME_ARR', 'ACTUALTIME_DEP', \n",
    "     'PASSENGERS', 'PASSENGERSIN', 'PASSENGERSOUT', 'DISTANCE', 'LASTUPDATE', 'NOTE']\n",
    "].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7278ea0d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad0591",
   "metadata": {},
   "source": [
    "<a id=\"duplicates_and_constants\"></a>\n",
    "## 1.3. Duplicates and Constants\n",
    "[Top of section](#data_quality_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519e406",
   "metadata": {},
   "source": [
    "### 1.3.1. Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of duplicate rows\n",
    "num_duplicate_rows = df_leavetimes.duplicated().sum()\n",
    "print(f\"There are {num_duplicate_rows} duplicated rows in this dataset (excluding the first row).\")\n",
    "num_duplicate_rows_inclusive = df_leavetimes[df_leavetimes.duplicated(keep=False)].shape[0]\n",
    "print(f\"There are {num_duplicate_rows_inclusive} duplicated rows in this dataset (including row that is duplicated).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c70d7f",
   "metadata": {},
   "source": [
    "> There are no duplicate rows in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e1e7a",
   "metadata": {},
   "source": [
    "### 1.3.2. Duplicate Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cd042",
   "metadata": {},
   "source": [
    "> There does not appear to be any duplicate columns in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e100a",
   "metadata": {},
   "source": [
    "### 1.3.3. Constant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d928b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print Categorical Descriptive Statistics\n",
    "df_leavetimes[categorical_columns].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf16fb6",
   "metadata": {},
   "source": [
    "> From this we see that DATASOURCE is a constant column as it only has 1 unique value, this will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b037626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the continuous features have a standard deviation greater than zero\n",
    "df_leavetimes[continuous_columns].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41145a",
   "metadata": {},
   "source": [
    "> From the standard deviation of the continuous features above we can see that PASSENGERS, PASSENGERSIN, PASSENGERSOUT, DISTANCE, and NOTE are constant columns of null values, these will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7103e6",
   "metadata": {},
   "source": [
    "### 1.3.4. Drop Constant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee28531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop constant columns\n",
    "constant_columns = [\n",
    "    'DATASOURCE', 'PASSENGERS', 'PASSENGERSIN', 'PASSENGERSOUT',\n",
    "    'DISTANCE', 'NOTE'\n",
    "]\n",
    "\n",
    "df_leavetimes = df_leavetimes.drop(columns=constant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c94cb",
   "metadata": {},
   "source": [
    "## Save Cleaned Data Frame - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "reordered_columns = [\n",
    "    'DAYOFSERVICE', 'LASTUPDATE', 'TRIPID', 'PROGRNUMBER', 'STOPPOINTID', \n",
    "    'VEHICLEID', 'JUSTIFICATIONID', 'SUPPRESSED',\n",
    "    'PLANNEDTIME_ARR', 'ACTUALTIME_ARR', \n",
    "    'PLANNEDTIME_DEP', 'ACTUALTIME_DEP',    \n",
    "]\n",
    "\n",
    "df_leavetimes = df_leavetimes[reordered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f35b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv\n",
    "df_leavetimes.to_csv('/home/faye/data/leavetimes_cleaned_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab698d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to feather\n",
    "df_leavetimes.to_feather('/home/faye/data/leavetimes_cleaned_1.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1fa4a",
   "metadata": {},
   "source": [
    "# Load Cleaned Data (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc71e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load in cleaned data from feather file\n",
    "df_leavetimes = pd.read_feather('/home/faye/data/leavetimes_cleaned_1.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c945d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYOFSERVICE</th>\n",
       "      <th>LASTUPDATE</th>\n",
       "      <th>TRIPID</th>\n",
       "      <th>PROGRNUMBER</th>\n",
       "      <th>STOPPOINTID</th>\n",
       "      <th>VEHICLEID</th>\n",
       "      <th>JUSTIFICATIONID</th>\n",
       "      <th>SUPPRESSED</th>\n",
       "      <th>PLANNEDTIME_ARR</th>\n",
       "      <th>ACTUALTIME_ARR</th>\n",
       "      <th>PLANNEDTIME_DEP</th>\n",
       "      <th>ACTUALTIME_DEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-08 17:21:10</td>\n",
       "      <td>5972116</td>\n",
       "      <td>12</td>\n",
       "      <td>119</td>\n",
       "      <td>2693211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>48030</td>\n",
       "      <td>48012</td>\n",
       "      <td>48030</td>\n",
       "      <td>48012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-08 17:21:10</td>\n",
       "      <td>5966674</td>\n",
       "      <td>12</td>\n",
       "      <td>119</td>\n",
       "      <td>2693267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>54001</td>\n",
       "      <td>54023</td>\n",
       "      <td>54001</td>\n",
       "      <td>54023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-08 17:21:10</td>\n",
       "      <td>5959105</td>\n",
       "      <td>12</td>\n",
       "      <td>119</td>\n",
       "      <td>2693263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>60001</td>\n",
       "      <td>59955</td>\n",
       "      <td>60001</td>\n",
       "      <td>59955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-08 17:21:10</td>\n",
       "      <td>5966888</td>\n",
       "      <td>12</td>\n",
       "      <td>119</td>\n",
       "      <td>2693284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>58801</td>\n",
       "      <td>58771</td>\n",
       "      <td>58801</td>\n",
       "      <td>58771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-08 17:21:10</td>\n",
       "      <td>5965960</td>\n",
       "      <td>12</td>\n",
       "      <td>119</td>\n",
       "      <td>2693209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>56401</td>\n",
       "      <td>56309</td>\n",
       "      <td>56401</td>\n",
       "      <td>56323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DAYOFSERVICE          LASTUPDATE   TRIPID PROGRNUMBER STOPPOINTID VEHICLEID  \\\n",
       "0   2018-01-01 2018-01-08 17:21:10  5972116          12         119   2693211   \n",
       "1   2018-01-01 2018-01-08 17:21:10  5966674          12         119   2693267   \n",
       "2   2018-01-01 2018-01-08 17:21:10  5959105          12         119   2693263   \n",
       "3   2018-01-01 2018-01-08 17:21:10  5966888          12         119   2693284   \n",
       "4   2018-01-01 2018-01-08 17:21:10  5965960          12         119   2693209   \n",
       "\n",
       "  JUSTIFICATIONID  SUPPRESSED  PLANNEDTIME_ARR  ACTUALTIME_ARR  \\\n",
       "0             NaN        <NA>            48030           48012   \n",
       "1             NaN        <NA>            54001           54023   \n",
       "2             NaN        <NA>            60001           59955   \n",
       "3             NaN        <NA>            58801           58771   \n",
       "4             NaN        <NA>            56401           56309   \n",
       "\n",
       "   PLANNEDTIME_DEP  ACTUALTIME_DEP  \n",
       "0            48030           48012  \n",
       "1            54001           54023  \n",
       "2            60001           59955  \n",
       "3            58801           58771  \n",
       "4            56401           56323  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leavetimes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "910a65f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYOFSERVICE       datetime64[ns]\n",
       "LASTUPDATE         datetime64[ns]\n",
       "TRIPID                   category\n",
       "PROGRNUMBER              category\n",
       "STOPPOINTID              category\n",
       "VEHICLEID                category\n",
       "JUSTIFICATIONID          category\n",
       "SUPPRESSED                boolean\n",
       "PLANNEDTIME_ARR             int64\n",
       "ACTUALTIME_ARR              int64\n",
       "PLANNEDTIME_DEP             int64\n",
       "ACTUALTIME_DEP              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leavetimes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d195b40",
   "metadata": {},
   "source": [
    "<a id=\"desc_stats_continuous\"></a>\n",
    "## 1.4. Descriptive Statistics for Continuous Features\n",
    "[Top of section](#data_quality_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns containing continuous data\n",
    "continuous_columns = df_leavetimes[\n",
    "    ['DAYOFSERVICE', 'LASTUPDATE',\n",
    "     'PLANNEDTIME_ARR', 'ACTUALTIME_ARR', \n",
    "     'PLANNEDTIME_DEP', 'ACTUALTIME_DEP']\n",
    "].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e1b86d",
   "metadata": {},
   "source": [
    "### 1.4.1. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46465a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print table with descriptive statistics for all the continuous features\n",
    "continuous_feat_desc = df_leavetimes[continuous_columns].describe(datetime_is_numeric=True).T\n",
    "\n",
    "print_bold(\"Descriptive Statistics for Continuous Features\")\n",
    "continuous_feat_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ae59b",
   "metadata": {},
   "source": [
    "> From the min and max for DAYOFSERVICE we can see that the data ranges from the 1st January to 31st December for the year 2018. By looking at the percentiles it also appears that the data is evenly spread throughout the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e0938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the min ACTUALTIME_ARR and max ACTUALTIME_DEP to HH:MM:SS\n",
    "print_bold(\"min ACTUALTIME_ARR and max ACTUALTIME_DEP\")\n",
    "print(datetime.timedelta(seconds=15974))\n",
    "print(datetime.timedelta(seconds=97177))\n",
    "# convert the median ACTUALTIME_ARR and ACTUALTIME_DEP to HH:MM:SS\n",
    "print_bold(\"median for ACTUALTIME_ARR and ACTUALTIME_DEP\")\n",
    "print(datetime.timedelta(seconds=53511))\n",
    "print(datetime.timedelta(seconds=53526))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ee485",
   "metadata": {},
   "source": [
    "> If we look at the min for ACTUALTIME_ARR and max for ACTUALTIME_DEP and convert the seconds to time we can see that the leave times range from 04:26 to 02:59 the following day. If we look at the median value for ACTUALTIME_ARR and ACTUALTIME_DEP it appears that the data is evenly spread throughout this range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa47d5e",
   "metadata": {},
   "source": [
    "### 1.4.2. Range of Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each continuous feature display the range of values and the number of instances for the 15 most common values\n",
    "for feat in continuous_columns:\n",
    "    \n",
    "    print_bold(feat)\n",
    "    print(\"Range {} is: {}\" .format( feat, (df_leavetimes[feat].max() - df_leavetimes[feat].min()) ) )\n",
    "    print(\"-\"*10)\n",
    "    \n",
    "    print_bold(\"{0:10.5} {1}\" .format(\"Value\", \"Number of Instances\") )\n",
    "    print(df_leavetimes[feat].value_counts().nlargest(15), \"\\n\\n\\n\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df00ab70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check for null values for each continuous feature\n",
    "print_bold(\"The sum of null values for Continuous Features\")\n",
    "print(\"-\"*50)\n",
    "print(df_leavetimes[continuous_columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16fccab",
   "metadata": {},
   "source": [
    "> From the above we can that we have no null values for the continuous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a4c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the cardinality of each continuous feature\n",
    "features_cardinality = list(df_leavetimes[continuous_columns].columns.values)\n",
    "\n",
    "print_bold(\"{0:35} {1}\" .format(\"Feature\",\"Cardinality\") )\n",
    "print(\"{0:35} {1}\" .format(\"-------\",\"-----------\") )\n",
    "\n",
    "for c in features_cardinality:\n",
    "    print(\"{0:35} {1}\" .format( c, (len(df_leavetimes[c].unique()))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923616b3",
   "metadata": {},
   "source": [
    "> We can see from the cardinality for DAYOFSERVICE that we have almost a full years worth of data for the leavetimes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336fd094",
   "metadata": {},
   "source": [
    "<a id=\"desc_stats_categorical\"></a>\n",
    "## 1.5. Descriptive Statistics for Categorical Features\n",
    "[Top of section](#data_quality_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns containing continuous data\n",
    "categorical_columns = df_leavetimes[\n",
    "    ['TRIPID', 'PROGRNUMBER', 'STOPPOINTID', 'VEHICLEID', \n",
    "     'JUSTIFICATIONID', 'SUPPRESSED']\n",
    "].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73620052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the descriptive statistics for all the categorical features\n",
    "categorical_feat_desc = df_leavetimes[categorical_columns].describe().T\n",
    "categorical_feat_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values for each categorical feature\n",
    "print_bold(\"The sum of null values for Continuous Features\")\n",
    "print(\"-\"*50)\n",
    "print(df_leavetimes[categorical_columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ddf7b",
   "metadata": {},
   "source": [
    "> From the above we can see that there is a very high number of entries with null values for the features JUSTIFICATIONID and SUPPRESSED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc06d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the % of null values for JUSTIFICATIONID and SUPPRESSED\n",
    "print_bold(\"The percentage of null values for JUSTIFICATIONID and SUPPRESSED\")\n",
    "print(\"-\"*50)\n",
    "print(\"{:20}{:.2f}\" .format(\"JUSTIFICATIONID\", df_leavetimes['JUSTIFICATIONID'].isnull().sum() / df_leavetimes.shape[0] * 100) )\n",
    "print(\"{:20}{:.2f}\" .format(\"SUPPRESSED\", df_leavetimes['SUPPRESSED'].isnull().sum() / df_leavetimes.shape[0] * 100) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e41422",
   "metadata": {},
   "source": [
    "> We have a extremely high number of missing values for both the JUSTIFICATIONID and SUPPRESSED feature.  \n",
    "I don't believe JUSTIFICATIONID will prove useful for modelling due to the high number of missing values and the fact it references to data which we do not have.  \n",
    "If we cannot infer the missing values for SUPPRESSED then I do not believe this feature will prove useful for any predictive modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0ef5ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frequency table for categorical features\n",
    "for feat in categorical_columns:\n",
    "    title = \"Frequency Table for \" + feat + \":\"\n",
    "    print_bold(title)\n",
    "    print(\"-\"*50)\n",
    "    print(df_leavetimes[feat].value_counts(normalize=True) * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca692f8",
   "metadata": {},
   "source": [
    "> Nearly three quarters of the values that we have for SUPPRESSED are False meaning the trips were achieved. 25% of these trips were suppressed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf99b8",
   "metadata": {},
   "source": [
    "<a id=\"plotting_continuous\"></a>\n",
    "## 1.6. Plotting Continuous Features\n",
    "[Top of section](#data_quality_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84200cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot histograms for continuous features\n",
    "df_leavetimes[continuous_columns].hist(layout=(2, 2), figsize=(30,30), bins=12)\n",
    "#plt.savefig('continuous_histograms_1-1.pdf')\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99748702",
   "metadata": {},
   "source": [
    "> From the plots above we can see that we have an increase in the number of entries where the arrival and departure times are around 30,000 and 60,000-70,000 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed032ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert seconds to HH:MM:SS\n",
    "print_bold(\"{:10}{}\" .format(\"Seconds\", \"HH:MM:SS\"))\n",
    "print(\"{:<10}{}\" .format(30000, datetime.timedelta(seconds=30000)))\n",
    "print(\"{:<10}{}\" .format(60000, datetime.timedelta(seconds=60000)))\n",
    "print(\"{:<10}{}\" .format(70000, datetime.timedelta(seconds=70000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ee88f",
   "metadata": {},
   "source": [
    "> These times are roughly correspond with rush hour times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97bf97",
   "metadata": {},
   "source": [
    "<a id=\"plotting_categorical\"></a>\n",
    "## 1.7. Plotting Categorical Features\n",
    "[Top of section](#data_quality_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926de59",
   "metadata": {},
   "source": [
    "> The only continuous feature I see any purpose in plotting is SUPPRESSED. I do not believe there is anything to gain from plotting the ID numbers or sequential stop number (PROGRNUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33a1e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the feature SUPPRESSED\n",
    "f = df_leavetimes['SUPPRESSED'].value_counts().plot(kind='bar', figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1e6f6",
   "metadata": {},
   "source": [
    "<a id=\"logical_integrity_check\"></a>\n",
    "## 1.8. Logical Integrity Check\n",
    "[Top of section](#data_quality_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a495eb3",
   "metadata": {},
   "source": [
    "### 1.8.1. Check 1: Check that LASTUPDATE > DAYOFSERVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for check 1\n",
    "check_1 = df_leavetimes[['DAYOFSERVICE','LASTUPDATE']][df_leavetimes['LASTUPDATE']<df_leavetimes['DAYOFSERVICE']]\n",
    "print(f\"Number of rows failing the check: {check_1.shape[0]}\")\n",
    "check_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf51da2",
   "metadata": {},
   "source": [
    "### 1.8.2. Check 2: Check that ACTUALTIME_DEP > ACTUALTIME_ARR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43e24ced",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows failing the check: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTUALTIME_ARR</th>\n",
       "      <th>ACTUALTIME_DEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74759275</th>\n",
       "      <td>46208</td>\n",
       "      <td>46207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81013777</th>\n",
       "      <td>39260</td>\n",
       "      <td>39258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86217868</th>\n",
       "      <td>71991</td>\n",
       "      <td>71989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ACTUALTIME_ARR  ACTUALTIME_DEP\n",
       "74759275           46208           46207\n",
       "81013777           39260           39258\n",
       "86217868           71991           71989"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe for check 2\n",
    "check_2 = df_leavetimes[['ACTUALTIME_ARR','ACTUALTIME_DEP']][df_leavetimes['ACTUALTIME_DEP']<df_leavetimes['ACTUALTIME_ARR']]\n",
    "print(f\"Number of rows failing the check: {check_2.shape[0]}\")\n",
    "check_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70238503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print \n",
    "df_leavetimes.iloc[[74759275,81013777,86217868]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e353f19a",
   "metadata": {},
   "source": [
    "<a id=\"data_quality_plan\"></a>\n",
    "# 2. Data Quality Plan\n",
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0042f181",
   "metadata": {},
   "source": [
    "<a id=\"the_plan\"></a>\n",
    "## 2.1. The Plan\n",
    "[Top of section](#data_quality_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ecdf6",
   "metadata": {},
   "source": [
    "| Variable Name           | Data Quality Issue | Handling Strategy      |\n",
    "| :---------------------- | :----------------- | :--------------------- |\n",
    "| DAYOFSERVICE            | none               | do nothing             |\n",
    "| LASTUPDATE              | irrelevant for modelling| drop feature      |\n",
    "| TRIPID                  | none               | do nothing             |\n",
    "| PROGRNUMBER             | none               | do nothing             |\n",
    "| STOPPOINTID             | none               | do nothing             |\n",
    "| VEHICLEID               | none               | do nothing             |\n",
    "| JUSTIFICATIONID         | 99.5% missing values| drop feature          |\n",
    "| SUPPRESSED              | 99.5% missing values| drop feature          |\n",
    "| PLANNEDTIME_ARR         | none               | do nothing             |\n",
    "| ACTUALTIME_ARR          | logical integrity  | swap with ACTUALTIME_DEP    |\n",
    "| PLANNEDTIME_DEP         | none               | do nothing             |\n",
    "| ACTUALTIME_DEP          | logical integrity  | swap with ACTUALTIME_ARR    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc4d097",
   "metadata": {},
   "source": [
    "<a id=\"applying_solutions\"></a>\n",
    "## 2.2. Applying the Solutions\n",
    "[Top of section](#data_quality_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb13f1",
   "metadata": {},
   "source": [
    "### 2.2.1. Drop Features: LASTUPDATE, JUSTIFICATIONID, and SUPPRESSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ceb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop features LASTUPDATE, JUSTIFICATIONID, and SUPPRESSED\n",
    "df_leavetimes = df_leavetimes.drop(columns=['LASTUPDATE','JUSTIFICATIONID','SUPPRESSED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f5bb30",
   "metadata": {},
   "source": [
    "### 2.2.2. Swap illogical rows from Logical Integrity Check 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38eb91cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTUALTIME_ARR</th>\n",
       "      <th>ACTUALTIME_DEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74759275</th>\n",
       "      <td>46208</td>\n",
       "      <td>46207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81013777</th>\n",
       "      <td>39260</td>\n",
       "      <td>39258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86217868</th>\n",
       "      <td>71991</td>\n",
       "      <td>71989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ACTUALTIME_ARR  ACTUALTIME_DEP\n",
       "74759275           46208           46207\n",
       "81013777           39260           39258\n",
       "86217868           71991           71989"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print rows failing logical integrity check\n",
    "df_leavetimes[['ACTUALTIME_ARR','ACTUALTIME_DEP']].iloc[[74759275,81013777,86217868]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c4c9670",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faye/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/faye/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# swap ACTUALTIME_ARR and ACTUALTIME_DEP values for illogical rows\n",
    "for i in check_2.index:\n",
    "    df_leavetimes['ACTUALTIME_ARR'][i] = check_2['ACTUALTIME_DEP'][i]\n",
    "    df_leavetimes['ACTUALTIME_DEP'][i] = check_2['ACTUALTIME_ARR'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeb04f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTUALTIME_ARR</th>\n",
       "      <th>ACTUALTIME_DEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74759275</th>\n",
       "      <td>46207</td>\n",
       "      <td>46208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81013777</th>\n",
       "      <td>39258</td>\n",
       "      <td>39260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86217868</th>\n",
       "      <td>71989</td>\n",
       "      <td>71991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ACTUALTIME_ARR  ACTUALTIME_DEP\n",
       "74759275           46207           46208\n",
       "81013777           39258           39260\n",
       "86217868           71989           71991"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check values have been swapped\n",
    "df_leavetimes[['ACTUALTIME_ARR','ACTUALTIME_DEP']].iloc[[74759275,81013777,86217868]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b1cd8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbadf9d",
   "metadata": {},
   "source": [
    "## Save Cleaned Data Frame - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c16a244",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1ab5ecda25d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save dataframe to csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_leavetimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/faye/data/leavetimes_cleaned_2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         )\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m             )\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    360\u001b[0m         )\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mlibwriters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mpandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# save dataframe to csv\n",
    "df_leavetimes.to_csv('/home/faye/data/leavetimes_cleaned_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d848abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to feather\n",
    "# !! doesn't work due to an index error\n",
    "df_leavetimes.to_feather('/home/faye/data/leavetimes_cleaned_2.feather', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf7eeb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c43d6c",
   "metadata": {},
   "source": [
    "# Load Cleaned Data (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3536a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned data from csv file\n",
    "df_leavetimes = pd.read_csv('/home/faye/data/leavetimes_cleaned_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd7903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in cleaned data from feather file\n",
    "df_leavetimes = pd.read_feather('/home/faye/data/leavetimes_cleaned_2.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1dd860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYOFSERVICE       object\n",
       "TRIPID              int64\n",
       "PROGRNUMBER         int64\n",
       "STOPPOINTID         int64\n",
       "VEHICLEID           int64\n",
       "PLANNEDTIME_ARR     int64\n",
       "ACTUALTIME_ARR      int64\n",
       "PLANNEDTIME_DEP     int64\n",
       "ACTUALTIME_DEP      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leavetimes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc28d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leavetimes['DAYOFSERVICE'] = pd.to_datetime(df_leavetimes['DAYOFSERVICE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "733dafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['TRIPID','PROGRNUMBER','STOPPOINTID','VEHICLEID']\n",
    "for col in cat_cols:\n",
    "    df_leavetimes[col] = df_leavetimes[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "451ddd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'DAYOFSERVICE', 'TRIPID', 'PROGRNUMBER', 'STOPPOINTID',\n",
       "       'VEHICLEID', 'PLANNEDTIME_ARR', 'ACTUALTIME_ARR', 'PLANNEDTIME_DEP',\n",
       "       'ACTUALTIME_DEP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leavetimes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2fb4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leavetimes = df_leavetimes.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe5f4795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYOFSERVICE       datetime64[ns]\n",
       "TRIPID                   category\n",
       "PROGRNUMBER              category\n",
       "STOPPOINTID              category\n",
       "VEHICLEID                category\n",
       "PLANNEDTIME_ARR             int64\n",
       "ACTUALTIME_ARR              int64\n",
       "PLANNEDTIME_DEP             int64\n",
       "ACTUALTIME_DEP              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leavetimes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bc77c5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c35bc5a",
   "metadata": {},
   "source": [
    "<a id=\"transforming_and_extending\"></a>\n",
    "# 3. Transforming and Extending Features\n",
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbabd7d4",
   "metadata": {},
   "source": [
    "New features to add:\n",
    "1. MONTH\n",
    "2. DAYOFWEEK\n",
    "3. DWELLTIME\n",
    "4. PLANNEDTIME_TRAVEL\n",
    "5. ACTUALTIME_TRAVEL\n",
    "6. IS_HOLIDAY\n",
    "7. IS_WEEKDAY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820d69a",
   "metadata": {},
   "source": [
    "<a id=\"add_month\"></a>\n",
    "## 3.1. Add feature: MONTH\n",
    "[Top of section](#transforming_and_extending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7d33b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add feature MONTHOFSERVICE\n",
    "df_leavetimes['MONTHOFSERVICE'] = df_leavetimes['DAYOFSERVICE'].dt.strftime('%B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ee1b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned data in feather file\n",
    "df_leavetimes.to_feather('/home/faye/data/leavetimes_1_extra_features.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819bb2dd",
   "metadata": {},
   "source": [
    "<a id=\"add_dayofweek\"></a>\n",
    "## 3.2. Add feature: DAYOFWEEK\n",
    "[Top of section](#transforming_and_extending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cd4ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add feature DAYOFWEEK\n",
    "df_leavetimes['DAYOFWEEK'] = [calendar.day_name[val.weekday()] for val in df_leavetimes['DAYOFSERVICE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fe8c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned data in feather file\n",
    "df_leavetimes.to_feather('/home/faye/data/leavetimes_2_extra_features.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea04737",
   "metadata": {},
   "source": [
    "<a id=\"add_dwelltime\"></a>\n",
    "## 3.3. Add feature: DWELLTIME\n",
    "[Top of section](#transforming_and_extending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33473dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add feature DWELLTIME\n",
    "df_leavetimes['DWELLTIME'] = df_leavetimes['ACTUALTIME_DEP'] - df_leavetimes['ACTUALTIME_ARR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eab89843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned data in feather file\n",
    "df_leavetimes.to_feather('/home/faye/data/leavetimes_3_extra_features.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e8bfc1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2135b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cleaned data in feather file\n",
    "df_leavetimes = pd.read_feather('/home/faye/data/leavetimes_3_extra_features.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16804c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYOFSERVICE       datetime64[ns]\n",
       "TRIPID                   category\n",
       "PROGRNUMBER              category\n",
       "STOPPOINTID              category\n",
       "VEHICLEID                category\n",
       "PLANNEDTIME_ARR             int64\n",
       "ACTUALTIME_ARR              int64\n",
       "PLANNEDTIME_DEP             int64\n",
       "ACTUALTIME_DEP              int64\n",
       "MONTHOFSERVICE             object\n",
       "DAYOFWEEK                  object\n",
       "DWELLTIME                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leavetimes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e306810c",
   "metadata": {},
   "source": [
    "<a id=\"add_plannedtime_travel\"></a>\n",
    "## 3.4. Add feature: PLANNEDTIME_TRAVEL\n",
    "[Top of section](#transforming_and_extending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4938c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data in feather file\n",
    "df_leavetimes = pd.read_feather('/home/faye/data/leavetimes_3_extra_features.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1915d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort sequentially by TRIPID, DAYOFSERVICE, PROGRNUMBER\n",
    "df_leavetimes = df_leavetimes.sort_values(['TRIPID','DAYOFSERVICE','PROGRNUMBER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8cc4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate planned travel time\n",
    "df_leavetimes['PLANNEDTIME_TRAVEL'] = (df_leavetimes['PLANNEDTIME_ARR']-df_leavetimes['PLANNEDTIME_DEP'].shift()).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "079d9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned data in feather file\n",
    "df_leavetimes.to_csv('/home/faye/data/leavetimes_4_extra_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627938c5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leavetimes = pd.read_csv('/home/faye/data/leavetimes_4_extra_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379cfa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce661798",
   "metadata": {},
   "source": [
    "<a id=\"add_actualtime_travel\"></a>\n",
    "## 3.5. Add feature: ACTUALTIME_TRAVEL\n",
    "[Top of section](#transforming_and_extending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5282c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate planned travel time\n",
    "df_leavetimes['ACTUALTIME_TRAVEL'] = (df_leavetimes['ACTUALTIME_ARR']-df_leavetimes['ACTUALTIME_DEP'].shift()).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61848df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned data in feather file\n",
    "df_leavetimes.to_feather('/home/faye/data/leavetimes_5_extra_features.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99dff28",
   "metadata": {},
   "source": [
    "<a id=\"add_isholiday\"></a>\n",
    "## 3.6. Add feature: IS_HOLIDAY\n",
    "[Top of section](#transforming_and_extending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0791b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a5738fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Irish holidays - including bank holidays\n",
    "# https://towardsdatascience.com/5-minute-guide-to-detecting-holidays-in-python-c270f8479387\n",
    "irish_holidays_2018 = []\n",
    "for date in holidays.Ireland(years=2018).items():\n",
    "    irish_holidays_2018.append(str(date[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8b26914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add feature IS_HOLIDAY\n",
    "df_leavetimes['IS_HOLIDAY'] = [1 if str(val).split()[0] in irish_holidays_2018 else 0 for val in df_leavetimes['DAYOFSERVICE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b8606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned data in feather file\n",
    "df_leavetimes.to_feather('/home/faye/data/leavetimes_6_extra_features.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a335f26",
   "metadata": {},
   "source": [
    "<a id=\"add_isweekday\"></a>\n",
    "## 3.7. Add feature: IS_WEEKDAY\n",
    "[Top of section](#transforming_and_extending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c0ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add feature IS_WEEKDAY\n",
    "df_leavetimes['IS_WEEKDAY'] = [1 if int(val.weekday()) < 5 else 0 for val in df_leavetimes['DAYOFSERVICE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e54360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned data in feather file\n",
    "df_leavetimes.to_feather('/home/faye/data/leavetimes_7_extra_features.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2711f9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d24496",
   "metadata": {},
   "source": [
    "# Reorder Columns and Save Dataset\n",
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9dbcab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYOFSERVICE          datetime64[ns]\n",
       "TRIPID                      category\n",
       "PROGRNUMBER                 category\n",
       "STOPPOINTID                 category\n",
       "VEHICLEID                   category\n",
       "PLANNEDTIME_ARR                int64\n",
       "ACTUALTIME_ARR                 int64\n",
       "PLANNEDTIME_DEP                int64\n",
       "ACTUALTIME_DEP                 int64\n",
       "MONTHOFSERVICE                object\n",
       "DAYOFWEEK                     object\n",
       "DWELLTIME                      int64\n",
       "PLANNEDTIME_TRAVEL           float64\n",
       "ACTUALTIME_TRAVEL            float64\n",
       "IS_HOLIDAY                     int64\n",
       "IS_WEEKDAY                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leavetimes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4af6997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "reorder_cols = [\n",
    "    'DAYOFSERVICE', 'DAYOFWEEK', 'MONTHOFSERVICE', 'TRIPID', 'PROGRNUMBER', 'STOPPOINTID', 'VEHICLEID',\n",
    "    'PLANNEDTIME_ARR', 'ACTUALTIME_ARR', 'PLANNEDTIME_DEP', 'ACTUALTIME_DEP', 'DWELLTIME',\n",
    "    'PLANNEDTIME_TRAVEL', 'ACTUALTIME_TRAVEL', 'IS_HOLIDAY', 'IS_WEEKDAY'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeaf0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv\n",
    "df_leavetimes.to_csv('/home/faye/data/leavetimes_extra_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061014f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save dataframe to feather\n",
    "df_leavetimes.to_feather('/home/faye/data/leavetimes_extra_features.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e18ef51",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fe140e",
   "metadata": {},
   "source": [
    "# Save dataframe to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6c2a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057b1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert continuous features to int32\n",
    "continuous_cols = [\n",
    "    'PLANNEDTIME_ARR', 'ACTUALTIME_ARR', 'PLANNEDTIME_DEP', 'ACTUALTIME_DEP', \n",
    "    'DWELLTIME', 'PLANNEDTIME_TRAVEL', 'ACTUALTIME_TRAVEL'\n",
    "]\n",
    "\n",
    "for col in continuous_cols:\n",
    "    df_leavetimes[col] = df_leavetimes[col].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7d4f6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8785ff",
   "metadata": {},
   "source": [
    "[Back to top](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
